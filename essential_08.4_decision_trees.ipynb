{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "- A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. \n",
    "- It has a hierarchical (top-down), tree structure, which consists of a root node, branches, internal nodes and leaf nodes.\n",
    "- it consists of nodes, there are threes typesof nodes:\n",
    "1. root node: entire population or sample\n",
    "2. decision node: conduct evaluations to form homogenous subsets\n",
    "3. leaf node: terminal nodes\n",
    "- Decision tree learning employs a divide and conquer strategy by conducting a greedy search   to identify the optimal split points within a tree. \n",
    "- greedy means the best split is down at that step and not in a forward looking way\n",
    "- This process of splitting is then repeated in a top-down, recursive manner until all, or the majority of records have been classified under specific class labels.\n",
    "- **Recursive binary splitting**: at ever decision node a predictor space in split in two segements/regions, it stops when user defined criteria are met. \n",
    "- Whether or not all data points are classified as homogenous sets is largely dependent on the complexity of the decision tree. As a tree grows in size too little data falls within a given subtree. When this occurs, it is known as **data fragmentation**, and it can often lead to **overfitting**. \n",
    "- As a result, decision trees have preference for small trees, which is consistent with the **principle of parsimony** in Occam’s Razor; that is, “entities should not be multiplied beyond necessity.”\n",
    "- To reduce complexity and prevent overfitting, **pruning** is usually employed; this is a process, which removes branches that split on features with low importance. Subtrees are replaced by leaf nodes. \n",
    "\n",
    "Pruning Methods: \n",
    "- Hold-ot-test (fast and simple)\n",
    "- Cost-complexity pruning, \n",
    "\n",
    "- The model’s fit can then be evaluated through the process of **cross-validation**. \n",
    "- Another way that decision trees can maintain their accuracy is by forming an ensemble via a **random forest** algorithm; this classifier predicts more accurate results, particularly when the individual trees are uncorrelated with each other.\n",
    "\n",
    "## Continous / Regression DT \n",
    "- predicts continous target\n",
    "- linear relationship between features and target\n",
    "- output from terminal/leaf nodes are the **mean response**, new datapoints are predicted from that mean.\n",
    "- In regression trees the splitting criteria is the $SSE= \\sum(y_i-\\bar{y})^2$ (sum of squared error) Loss function.\n",
    "- At every stage in the regression tree the region is split in two, such that the SSE is minimized.\n",
    "\n",
    "- **Classification / Rategorical DT** predicts binary categories\n",
    "- Classification uses the Gini-index to calulate the Loss Function and the best split. \n",
    "- output values from terminal nodes, represent the **mode response**, new values will be predicted from that mode\n",
    "- Recursive Splitting in a classification tree splits regions in two according to a user defined metric, for example the Gini index G.\n",
    "- **Gini Index**, also known as Gini impurity, calculates the probability misclassification.. \n",
    "- If all the elements are linked with a single class then it can be called **pure**.\n",
    "- Gini index varies between [0,1], where \n",
    "- 0 expresses the purity: all the elements belong to a specified class or only one class exists there. \n",
    "- 1 indicates the random distribution of elements across various classes. \n",
    "- The value of 0.5 of the Gini Index shows an equal distribution of elements over some classes.\n",
    "- The Gini Index tends to have a preference for larger partitions and hence can be computationally intensive.\n",
    "\n",
    "### Advantages: \n",
    "- DT are can process non-linear data, \n",
    "- are easy to interpret, -\n",
    "- graphically representable, \n",
    "- and require less data prepartion\n",
    "\n",
    "### Disadvantages: \n",
    "- very non-robust \n",
    "- sensitive to training data\n",
    "- globally optimum tree not guaranteed\n",
    "\n",
    "### Assumptions: \n",
    "- rote node = entire trainig set\n",
    "- predictive features are either categorical or if continous they're binned prior to model deplyoyment\n",
    "- rows in the dataset have a recursive distribution based on the values of the attributes\n",
    "\n",
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lillian\\\\Anaconda3;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Scripts;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Users\\\\Lillian\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"path\"]=os.environ[\"path\"]+\";C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lillian\\\\Anaconda3;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\Lillian\\\\Anaconda3\\\\Scripts;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Windows\\\\System32\\\\OpenSSH\\\\;C:\\\\Users\\\\Lillian\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris=datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns= iris.feature_names)\n",
    "\n",
    "y = pd.DataFrame(iris.target)\n",
    "\n",
    "y.columns = ['labels']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(dtree, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "90e46ec4b387b633a89cba001294dbacbdc2d7a1806327e4b9e9ce73f0e3d3ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
